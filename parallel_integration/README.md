# Parallelizing Numeric Integration

Here are the OpenMp/CUDA examples from class on numerically computing an integral:

 - [Sequentially computing a numeric integral on CPU](https://lawlor.cs.uaf.edu/netrun/run?name=Testing&code=float%20foo%28%29%20%7B%0D%0A%09int%20n%3D10000000%3B%0D%0A%09float%20lo%20%3D%202.0%2C%20hi%20%3D%204.0%3B%0D%0A%09float%20dx%20%3D%20%28hi%20-%20lo%29%20%2F%20n%3B%0D%0A%09%0D%0A%09double%20total%20%3D%200.0%3B%0D%0A%09%0D%0A%09for%28int%20i%20%3D%200%3B%20i%20%3C%20n%3B%20%2B%2Bi%29%20%7B%0D%0A%09%09float%20x%20%3D%20lo%20%2B%20dx%20%2A%20i%3B%0D%0A%09%09float%20f%20%3D%20expf%28x%29%20%2A%20logf%28x%29%3B%0D%0A%09%09total%20%2B%3D%20f%20%2A%20dx%3B%0D%0A%09%7D%0D%0A%09%0D%0A%09return%20total%3B%0D%0A%7D&lang=C%2B%2B0x&mach=skylake64&mode=file&input=&linkwith=&foo_ret=float&foo_arg0=void&orun=Run&orun=Grade&orun=Time&ocompile=Optimize&ocompile=Warnings)
 - [Computing numeric integral on CPU with OpenMP](https://lawlor.cs.uaf.edu/netrun/run?name=Testing&code=float%20foo%28%29%20%7B%0D%0A%09int%20n%3D10000000%3B%0D%0A%09float%20lo%20%3D%202.0%2C%20hi%20%3D%204.0%3B%0D%0A%09float%20dx%20%3D%20%28hi%20-%20lo%29%20%2F%20n%3B%0D%0A%09%0D%0A%09double%20total%20%3D%200.0%3B%0D%0A%09%0D%0A%09%23pragma%20omp%20parallel%20for%20reduction%28%2B%3Atotal%29%0D%0A%09for%28int%20i%20%3D%200%3B%20i%20%3C%20n%3B%20%2B%2Bi%29%20%7B%0D%0A%09%09float%20x%20%3D%20lo%20%2B%20dx%20%2A%20i%3B%0D%0A%09%09float%20f%20%3D%20expf%28x%29%20%2A%20logf%28x%29%3B%0D%0A%09%09total%20%2B%3D%20f%20%2A%20dx%3B%0D%0A%09%7D%0D%0A%09%0D%0A%09return%20total%3B%0D%0A%7D&lang=C%2B%2B0x&mach=skylake64&mode=file&input=&linkwith=&foo_ret=float&foo_arg0=void&orun=Run&orun=Grade&orun=Time&ocompile=Optimize&ocompile=Warnings)
 - [Computing area of rectangles under curve (but not summing up to get integral) on GPU](https://lawlor.cs.uaf.edu/netrun/run?name=Testing&code=enum%20%7B%20MAX_COUNT%20%3D%2010000000%20%7D%3B%0D%0A%0D%0A%0D%0A__global__%20void%20do_work%28float%2A%20results%2C%20float%20low%2C%20float%20dx%29%20%7B%0D%0A%09long%20i%20%3D%20threadIdx.x%20%2B%20blockIdx.x%20%2A%20blockDim.x%3B%0D%0A%09%0D%0A%09float%20x%20%3D%20low%20%2B%20dx%20%2A%20i%3B%0D%0A%09results%5Bi%5D%20%3D%20expf%28x%29%20%2A%20logf%28x%29%20%2A%20dx%3B%0D%0A%7D%0D%0A%0D%0Adouble%20foo%28%29%20%7B%0D%0A%09long%20blockSize%20%3D%20100%3B%0D%0A%09long%20blocks%20%3D%20MAX_COUNT%20%2F%20blockSize%3B%0D%0A%09%0D%0A%09float%20low%20%3D%202.0%3B%0D%0A%09float%20high%20%3D%204.0%3B%0D%0A%09float%20dx%20%3D%20%28high%20-%20low%29%20%2F%20MAX_COUNT%3B%0D%0A%09%0D%0A%09float%2A%20gpu_results%3B%0D%0A%09cudaMalloc%28%26gpu_results%2C%20MAX_COUNT%20%2A%20sizeof%28float%29%29%3B%0D%0A%0D%0A%09double%20total%20%3D%200.0%3B%0D%0A%09%0D%0A%09double%20start%20%3D%20time_in_seconds%28%29%3B%0D%0A%09%0D%0A%09do_work%3C%3C%3Cblocks%2CblockSize%3E%3E%3E%28gpu_results%2C%20low%2C%20dx%29%3B%0D%0A%09cudaDeviceSynchronize%28%29%3B%0D%0A%09%0D%0A%09double%20end%20%3D%20time_in_seconds%28%29%3B%0D%0A%09std%3A%3Acout%20%3C%3C%20%22Time%20per%20thread%3A%20%22%20%3C%3C%20%28end%20-%20start%29%20%2A%201000.0%20%2A%201000.0%20%2A%201000.0%20%2F%20%28MAX_COUNT%29%20%3C%3C%20%22ns%5Cn%22%3B%0D%0A%09%0D%0A%09return%20total%3B%0D%0A%7D&lang=CUDA&mach=skylake64&mode=file&input=&linkwith=&foo_ret=double&foo_arg0=void&orun=Run&orun=Grade&ocompile=Optimize&ocompile=Warnings)
 - [Computing area of rectangles under curve on GPU then copying all areas to sum on CPU](https://lawlor.cs.uaf.edu/netrun/run?name=Testing&code=enum%20%7B%20MAX_COUNT%20%3D%2010000000%20%7D%3B%0D%0A%0D%0A%0D%0A__global__%20void%20do_work%28float%2A%20results%2C%20float%20low%2C%20float%20dx%29%20%7B%0D%0A%09long%20i%20%3D%20threadIdx.x%20%2B%20blockIdx.x%20%2A%20blockDim.x%3B%0D%0A%09%0D%0A%09float%20x%20%3D%20low%20%2B%20dx%20%2A%20i%3B%0D%0A%09results%5Bi%5D%20%3D%20expf%28x%29%20%2A%20logf%28x%29%20%2A%20dx%3B%0D%0A%7D%0D%0A%0D%0Adouble%20foo%28%29%20%7B%0D%0A%09long%20blockSize%20%3D%20100%3B%0D%0A%09long%20blocks%20%3D%20MAX_COUNT%20%2F%20blockSize%3B%0D%0A%09%0D%0A%09float%20low%20%3D%202.0%3B%0D%0A%09float%20high%20%3D%204.0%3B%0D%0A%09float%20dx%20%3D%20%28high%20-%20low%29%20%2F%20MAX_COUNT%3B%0D%0A%09%0D%0A%09float%2A%20gpu_results%3B%0D%0A%09cudaMalloc%28%26gpu_results%2C%20MAX_COUNT%20%2A%20sizeof%28float%29%29%3B%0D%0A%0D%0A%09float%2A%20cpu_results%20%3D%20new%20float%5BMAX_COUNT%5D%3B%0D%0A%0D%0A%09double%20total%20%3D%200.0%3B%0D%0A%09%0D%0A%09double%20start%20%3D%20time_in_seconds%28%29%3B%0D%0A%09%0D%0A%09do_work%3C%3C%3Cblocks%2CblockSize%3E%3E%3E%28gpu_results%2C%20low%2C%20dx%29%3B%0D%0A%09cudaDeviceSynchronize%28%29%3B%0D%0A%09cudaMemcpy%28cpu_results%2C%20gpu_results%2C%20MAX_COUNT%20%2A%20sizeof%28float%29%2C%20cudaMemcpyDeviceToHost%29%3B%0D%0A%09for%28int%20i%20%3D%200%3B%20i%20%3C%20MAX_COUNT%3B%20%2B%2Bi%29%20%7B%0D%0A%09%09total%20%2B%3D%20cpu_results%5Bi%5D%3B%0D%0A%09%7D%0D%0A%09%0D%0A%09double%20end%20%3D%20time_in_seconds%28%29%3B%0D%0A%09std%3A%3Acout%20%3C%3C%20%22Time%20per%20thread%3A%20%22%20%3C%3C%20%28end%20-%20start%29%20%2A%201000.0%20%2A%201000.0%20%2A%201000.0%20%2F%20%28MAX_COUNT%29%20%3C%3C%20%22ns%5Cn%22%3B%0D%0A%09%0D%0A%09return%20total%3B%0D%0A%7D&lang=CUDA&mach=skylake64&mode=file&input=&linkwith=&foo_ret=double&foo_arg0=void&orun=Run&orun=Grade&ocompile=Optimize&ocompile=Warnings)
 - [Computing numeric integral on GPU using a single accumulator and atomicAdd](https://lawlor.cs.uaf.edu/netrun/run?name=Testing&code=enum%20%7B%20MAX_COUNT%20%3D%2010000000%20%7D%3B%0D%0A%0D%0A%0D%0A__global__%20void%20do_work%28float%2A%20total%2C%20float%20low%2C%20float%20dx%29%20%7B%0D%0A%09long%20i%20%3D%20threadIdx.x%20%2B%20blockIdx.x%20%2A%20blockDim.x%3B%0D%0A%09%0D%0A%09float%20x%20%3D%20low%20%2B%20dx%20%2A%20i%3B%0D%0A%09atomicAdd%28total%2C%20expf%28x%29%20%2A%20logf%28x%29%20%2A%20dx%29%3B%0D%0A%7D%0D%0A%0D%0Adouble%20foo%28%29%20%7B%0D%0A%09long%20blockSize%20%3D%20100%3B%0D%0A%09long%20blocks%20%3D%20MAX_COUNT%20%2F%20blockSize%3B%0D%0A%09%0D%0A%09float%20low%20%3D%202.0%3B%0D%0A%09float%20high%20%3D%204.0%3B%0D%0A%09float%20dx%20%3D%20%28high%20-%20low%29%20%2F%20MAX_COUNT%3B%0D%0A%09%0D%0A%09float%2A%20gpu_total%3B%0D%0A%09%2F%2FcudaMalloc%28%26gpu_results%2C%20MAX_COUNT%20%2A%20sizeof%28float%29%29%3B%0D%0A%09cudaMalloc%28%26gpu_total%2C%20sizeof%28float%29%29%3B%0D%0A%09%0D%0A%09%2F%2Ffloat%2A%20cpu_results%20%3D%20new%20float%5BMAX_COUNT%5D%3B%0D%0A%09%2F%2Ffloat%20cpu_results%3B%0D%0A%09%0D%0A%09float%20total%20%3D%200.0%3B%0D%0A%09%0D%0A%09double%20start%20%3D%20time_in_seconds%28%29%3B%0D%0A%09%0D%0A%09do_work%3C%3C%3Cblocks%2CblockSize%3E%3E%3E%28gpu_total%2C%20low%2C%20dx%29%3B%0D%0A%09cudaDeviceSynchronize%28%29%3B%0D%0A%09cudaMemcpy%28%26total%2C%20gpu_total%2C%20sizeof%28float%29%2C%20cudaMemcpyDeviceToHost%29%3B%0D%0A%09%2F%2Ffor%28int%20i%20%3D%200%3B%20i%20%3C%20MAX_COUNT%3B%20%2B%2Bi%29%20%7B%0D%0A%09%2F%2F%09total%20%2B%3D%20cpu_results%5Bi%5D%3B%0D%0A%09%2F%2F%7D%0D%0A%09%0D%0A%09double%20end%20%3D%20time_in_seconds%28%29%3B%0D%0A%09std%3A%3Acout%20%3C%3C%20%22Time%20per%20thread%3A%20%22%20%3C%3C%20%28end%20-%20start%29%20%2A%201000.0%20%2A%201000.0%20%2A%201000.0%20%2F%20%28MAX_COUNT%29%20%3C%3C%20%22ns%5Cn%22%3B%0D%0A%09%0D%0A%09return%20total%3B%0D%0A%7D&lang=CUDA&mach=skylake64&mode=file&input=&linkwith=&foo_ret=double&foo_arg0=void&orun=Run&orun=Grade&ocompile=Optimize&ocompile=Warnings)
 - [Computing numeric integral on GPU using an array of accumulators and atomicAdd (BEST VERSION!)](https://lawlor.cs.uaf.edu/netrun/run?name=Testing&code=enum%20%7B%20MAX_COUNT%20%3D%2010000000%20%7D%3B%0D%0A%0D%0A%0D%0A__global__%20void%20do_work%28float%2A%20results%2C%20float%20low%2C%20float%20dx%29%20%7B%0D%0A%09long%20i%20%3D%20threadIdx.x%20%2B%20blockIdx.x%20%2A%20blockDim.x%3B%0D%0A%09%0D%0A%09float%20x%20%3D%20low%20%2B%20dx%20%2A%20i%3B%0D%0A%09atomicAdd%28%26results%5Bi%20%25%201024%5D%2C%20expf%28x%29%20%2A%20logf%28x%29%20%2A%20dx%29%3B%0D%0A%7D%0D%0A%0D%0Adouble%20foo%28%29%20%7B%0D%0A%09long%20blockSize%20%3D%20100%3B%0D%0A%09long%20blocks%20%3D%20MAX_COUNT%20%2F%20blockSize%3B%0D%0A%09%0D%0A%09long%20outSize%20%3D%201024%3B%0D%0A%09%0D%0A%09float%20low%20%3D%202.0%3B%0D%0A%09float%20high%20%3D%204.0%3B%0D%0A%09float%20dx%20%3D%20%28high%20-%20low%29%20%2F%20MAX_COUNT%3B%0D%0A%09%0D%0A%09float%2A%20gpu_results%3B%0D%0A%09cudaMalloc%28%26gpu_results%2C%20outSize%20%2A%20sizeof%28float%29%29%3B%0D%0A%0D%0A%09float%2A%20cpu_results%20%3D%20new%20float%5BoutSize%5D%3B%0D%0A%0D%0A%09double%20total%20%3D%200.0%3B%0D%0A%09%0D%0A%09double%20start%20%3D%20time_in_seconds%28%29%3B%0D%0A%09%0D%0A%09do_work%3C%3C%3Cblocks%2CblockSize%3E%3E%3E%28gpu_results%2C%20low%2C%20dx%29%3B%0D%0A%09cudaDeviceSynchronize%28%29%3B%0D%0A%09cudaMemcpy%28cpu_results%2C%20gpu_results%2C%20outSize%20%2A%20sizeof%28float%29%2C%20cudaMemcpyDeviceToHost%29%3B%0D%0A%09for%28int%20i%20%3D%200%3B%20i%20%3C%20outSize%3B%20%2B%2Bi%29%20%7B%0D%0A%09%09total%20%2B%3D%20cpu_results%5Bi%5D%3B%0D%0A%09%7D%0D%0A%09%0D%0A%09double%20end%20%3D%20time_in_seconds%28%29%3B%0D%0A%09std%3A%3Acout%20%3C%3C%20%22Time%20per%20thread%3A%20%22%20%3C%3C%20%28end%20-%20start%29%20%2A%201000.0%20%2A%201000.0%20%2A%201000.0%20%2F%20%28MAX_COUNT%29%20%3C%3C%20%22ns%5Cn%22%3B%0D%0A%09%0D%0A%09return%20total%3B%0D%0A%7D&lang=CUDA&mach=skylake64&mode=file&input=&linkwith=&foo_ret=double&foo_arg0=void&orun=Run&orun=Grade&ocompile=Optimize&ocompile=Warnings)
